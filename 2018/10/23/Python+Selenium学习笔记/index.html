<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="My personal blog">
    <meta name="keyword" content="">
    <meta name="theme-color" content="#600090">
    <meta name="msapplication-navbutton-color" content="#600090">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="#600090">
    <link rel="shortcut icon" href="https://cdn4.iconfinder.com/data/icons/ionicons/512/icon-person-128.png">
    <link rel="alternate" type="application/atom+xml" title="Baobiy" href="/atom.xml">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/animate.css/3.5.2/animate.min.css">
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.css">
    <title>
        
        Python+Selenium学习笔记｜undefined
        
    </title>

    <link rel="canonical" href="http://yoursite.com/2018/10/23/Python+Selenium学习笔记/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/blog-style.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/css/syntax.css">
</head>

<style>

    header.intro-header {
        background-image: url('')
    }
</style>
<!-- hack iOS CSS :active style -->
<body ontouchstart="" class="animated fadeIn">
<!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top " id="nav-top" data-ispost = "true" data-istags="false
" data-ishome = "false" >
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand animated pulse" href="/">
                <span class="brand-logo">
                    Baobiy
                </span>
                's Blog
            </a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <!-- /.navbar-collapse -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>
					
                    
					
					
                </ul>
            </div>
        </div>
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
//    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>

<!-- Main Content -->

<!--only post-->


<img class="wechat-title-img" src="">


<style>
    
    header.intro-header {
        background-image: url('');
    }

    
</style>

<header class="intro-header">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 text-center">
                <div class="post-heading">
                    <h1>Python+Selenium学习笔记</h1>
                    
                    <h2 class="subheading">Python+Selenium</h2>
                    
                    <span class="meta">
                         作者 Baobiy
                        <span>
                          日期 2018-10-23
                         </span>
                    </span>
                    <div class="tags text-center">
                        
                        <a class="tag" href="/tags/#Python"
                           title="Python">Python</a>
                        
                        <a class="tag" href="/tags/#Selenium"
                           title="Selenium">Selenium</a>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="post-title-haojen">
        <span>
            Python+Selenium学习笔记
        </span>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">
            <!-- Post Container -->
            <div class="col-lg-8 col-lg-offset-1 col-sm-9 post-container">
                <p>相关Blog： </p>
<p>推荐专栏：专栏：Python Selenium自动化测试详解 - CSDN博客  <a href="https://blog.csdn.net/column/details/12694.html" target="_blank" rel="noopener">https://blog.csdn.net/column/details/12694.html</a></p>
<p>Python3 Selenium自动化web测试 ==&gt; 第三节 常用WebDriver API使用示例上（24个API） - 脚本_驱动_测试 - 博客园  <a href="https://www.cnblogs.com/wuzhiming/p/8860087.html" target="_blank" rel="noopener">https://www.cnblogs.com/wuzhiming/p/8860087.html</a></p>
<p>python selenium-webdriver 元素操作之键盘操作（五） - 梦雨情殇 - 博客园  <a href="https://www.cnblogs.com/mengyu/p/6942584.html" target="_blank" rel="noopener">https://www.cnblogs.com/mengyu/p/6942584.html</a></p>
<p>python3 selenium使用 - 大黑马 - 博客园  <a href="https://www.cnblogs.com/QI1125/p/7852661.html" target="_blank" rel="noopener">https://www.cnblogs.com/QI1125/p/7852661.html</a></p>
<p>在selenium中使用css选择器进行元素定位 - grace666的专栏 - CSDN博客  <a href="https://blog.csdn.net/grace666/article/details/48419529/" target="_blank" rel="noopener">https://blog.csdn.net/grace666/article/details/48419529/</a></p>
<p>Python3中Selenium使用方法<em>搜狐科技</em>搜狐网  <a href="http://www.sohu.com/a/144251028_572440" target="_blank" rel="noopener">http://www.sohu.com/a/144251028_572440</a></p>
<h1 id="selenium模块的基本用法"><a href="#selenium模块的基本用法" class="headerlink" title="selenium模块的基本用法"></a>selenium模块的基本用法</h1><h2 id="查找元素"><a href="#查找元素" class="headerlink" title="查找元素"></a>查找元素</h2><pre><code>单个元素   (from selenium import webdriver)
    brguge.find_element_by_id(&apos;q&apos;)用这个元素找id是q的元素
    brguge.find_element_by_css_selector(&apos;#q&apos;)找css样式是q的
    brguge.find_element_by_xpath(&apos;//*[ @id=&quot;q&quot;]&apos;)三个效果一样
    brguge.find_element_by_name()通过name来查找
    brguge.find_element_by_link_text()通过link来查找
    brguge.find_element_by_partial_link_text()
    brguge.find_element_by_tag_name()
    brguge.find_element_by_class_name()通过class查找

    from selenium import webdriver
    from selenium.webdriver.common.by import By
    brguge.find_element(By.ID,&apos;Q&apos;)通用查找方式
多个元素（find_elements）加了个s
    他会以列表的形式打印出来
    brguge.find_elements_by_css_selector(&apos;.service-bd li&apos;)css样式为li的元素
    brguge.find_elements（By.css_selector,&apos;.service-bd li&apos;）两个作用一样
    (利用索引就可以获取单个或多个元素了)

元素交互操作（获取元素然后再给他指令）
    选择输入框 --》send_keys(&apos;输入文字&apos;)--》clear()清空输入框--在输入别的--》找到搜索--》click(点击)
    input.clear()清空按钮
交互动作（将动作附加到动作链中串行执行）
    switch_to_frame(&apos;iframeResult&apos;)
    用css样式分别找到两个要交互
    调用ActionChains(调用谷歌的)
    drag_and_drop(source,target)第一个到第二个上面
    perform()
</code></pre><h2 id="元素操作之键盘操作"><a href="#元素操作之键盘操作" class="headerlink" title="元素操作之键盘操作"></a>元素操作之键盘操作</h2><p>selenium 提供了比较完整的键盘操作，在使用的模拟键盘操作之前需要我们导入</p>
<p>from selenium.webdriver.common.keys import Keys即可，然后就可以来模拟键盘操作。</p>
<pre><code>#导入Keys 模块，然后我们看看Keys 模块定义了那些按键
from selenium.webdriver.common.keys import Keys
</code></pre><p>导入模块以后，我们可以看看具体的定义按键内容，我已经把经常使用的按键注释标记。</p>
<pre><code>NULL = &apos;\ue000&apos;
CANCEL = &apos;\ue001&apos;  # ^break
HELP = &apos;\ue002&apos;
BACKSPACE = &apos;\ue003&apos;
BACK_SPACE = BACKSPACE   #删除键
TAB = &apos;\ue004&apos;   #TAB键
CLEAR = &apos;\ue005&apos;  
RETURN = &apos;\ue006&apos;
ENTER = &apos;\ue007&apos;   #回车键
SHIFT = &apos;\ue008&apos;   #Shift键
LEFT_SHIFT = SHIFT
CONTROL = &apos;\ue009&apos;
LEFT_CONTROL = CONTROL   #Ctrl 键
ALT = &apos;\ue00a&apos;           #Alt 键
LEFT_ALT = ALT
PAUSE = &apos;\ue00b&apos;
ESCAPE = &apos;\ue00c&apos;   #ECS键
SPACE = &apos;\ue00d&apos;    #空格键 
PAGE_UP = &apos;\ue00e&apos;   #PgUp 键
PAGE_DOWN = &apos;\ue00f&apos; #PgDwon 键
END = &apos;\ue010&apos;    #END 键
HOME = &apos;\ue011&apos;   #HOME 键
LEFT = &apos;\ue012&apos;  #左键
ARROW_LEFT = LEFT  
UP = &apos;\ue013&apos;    #上键
ARROW_UP = UP   
RIGHT = &apos;\ue014&apos;
ARROW_RIGHT = RIGHT  #右键
DOWN = &apos;\ue015&apos;      #下键
ARROW_DOWN = DOWN  
INSERT = &apos;\ue016&apos;    #insert键 
DELETE = &apos;\ue017&apos;    #del键

SEMICOLON = &apos;\ue018&apos;  #&apos;;&apos;键
EQUALS = &apos;\ue019&apos;     #&apos;=&apos;键

数字键盘
NUMPAD0 = &apos;\ue01a&apos;  # number pad keys
NUMPAD1 = &apos;\ue01b&apos;
NUMPAD2 = &apos;\ue01c&apos;
NUMPAD3 = &apos;\ue01d&apos;
NUMPAD4 = &apos;\ue01e&apos;
NUMPAD5 = &apos;\ue01f&apos;
NUMPAD6 = &apos;\ue020&apos;
NUMPAD7 = &apos;\ue021&apos;
NUMPAD8 = &apos;\ue022&apos;
NUMPAD9 = &apos;\ue023&apos;
MULTIPLY = &apos;\ue024&apos; # &apos;*&apos; 键
ADD = &apos;\ue025&apos;   # &apos;+&apos; 键
SEPARATOR = &apos;\ue026&apos;  #&apos;,&apos;键
SUBTRACT = &apos;\ue027&apos;  # &apos;-&apos; 键
DECIMAL = &apos;\ue028&apos;   # &apos;.&apos;键
DIVIDE = &apos;\ue029&apos;    #&apos;/&apos;键

F1 = &apos;\ue031&apos;  # function  keys
F2 = &apos;\ue032&apos;
F3 = &apos;\ue033&apos;
F4 = &apos;\ue034&apos;
F5 = &apos;\ue035&apos;
F6 = &apos;\ue036&apos;
F7 = &apos;\ue037&apos;
F8 = &apos;\ue038&apos;
F9 = &apos;\ue039&apos;
F10 = &apos;\ue03a&apos;
F11 = &apos;\ue03b&apos;
F12 = &apos;\ue03c&apos;

META = &apos;\ue03d&apos;
COMMAND = &apos;\ue03d&apos;
</code></pre><p><strong>几个常用的组合键</strong></p>
<pre><code>send_keys(Keys.CONTROL,&apos;a&apos;) 　　#全选（Ctrl+A）

send_keys(Keys.CONTROL,&apos;c&apos;) 　　#复制（Ctrl+C）

send_keys(Keys.CONTROL,&apos;x&apos;) 　　#剪切（Ctrl+X）

send_keys(Keys.CONTROL,&apos;v&apos;) 　　#粘贴（Ctrl+V）
</code></pre><p><strong>下面常用的键，这些常用键主要是非组合键，直接输入即可</strong></p>
<pre><code>回车键 Keys.ENTER
删除键 Keys.BACK_SPACE
空格键 Keys.SPACE
制表键 Keys.TAB
回退键 Keys.ESCAPE
刷新键 Keys.F5
</code></pre><h1 id="对于百度设置拦定位的问题"><a href="#对于百度设置拦定位的问题" class="headerlink" title="对于百度设置拦定位的问题"></a>对于百度设置拦定位的问题</h1><h2 id="问题1：Firefox直接选择点击设置，再次点击下拉拦是无法定位到的。（同样方法在Chrome中可定位到）"><a href="#问题1：Firefox直接选择点击设置，再次点击下拉拦是无法定位到的。（同样方法在Chrome中可定位到）" class="headerlink" title="问题1：Firefox直接选择点击设置，再次点击下拉拦是无法定位到的。（同样方法在Chrome中可定位到）"></a>问题1：Firefox直接选择点击设置，再次点击下拉拦是无法定位到的。（同样方法在Chrome中可定位到）</h2><pre><code>解决办法：使用鼠标悬停“设置”一元素，再定位下拉元素，可正常定位
详见链接：selenium弹窗定位百度主页“设置”问题 - 痞子斗流氓 - 博客园  http://www.cnblogs.com/Testcase/p/9498217.html

且此时第二元素使用xpath时，报错无法找到该元素（可能跟firfox定位时长有关系）
</code></pre><h2 id="问题2：定位时使用xpath，或css-selector定位不到，也会报错。"><a href="#问题2：定位时使用xpath，或css-selector定位不到，也会报错。" class="headerlink" title="问题2：定位时使用xpath，或css_selector定位不到，也会报错。"></a>问题2：定位时使用xpath，或css_selector定位不到，也会报错。</h2><pre><code>解决：使用link_text定位（更清晰）
</code></pre><p><strong>完整代码：</strong></p>
<pre><code>from selenium import webdriver
import time
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support.select import Select

driver = webdriver.Firefox()
driver.get(&apos;http://www.baidu.com&apos;)
driver.implicitly_wait(30)

mouse = driver.find_element_by_css_selector(&apos;#u1 &gt; a.pf&apos;)
ActionChains(driver).move_to_element(mouse).perform()
time.sleep(2)

driver.find_element_by_link_text(&apos;搜索设置&apos;).click()
time.sleep(3)

option = driver.find_element_by_id(&apos;nr&apos;)
s = Select(option)
s.select_by_value(&apos;20&apos;)
time.sleep(3)

driver.find_element_by_link_text(&apos;保存设置&apos;).click()
alert = driver.switch_to_alert()
print(alert.text)
alert.accept()
time.sleep(2)

driver.quit()    
</code></pre><h2 id="问题3：网页通知（告警）弹窗接收问题"><a href="#问题3：网页通知（告警）弹窗接收问题" class="headerlink" title="问题3：网页通知（告警）弹窗接收问题"></a>问题3：网页通知（告警）弹窗接收问题</h2><pre><code>参考链接：selenium+webdriver+python 中警告框的处理方法 - 在路上 - CSDN博客  https://blog.csdn.net/liujingqiu/article/details/51209374

webdriver 中处理JavaScript 所生成的alert、confirm 以及prompt 是很简单的。具体思路是使用
switch_to.alert()方法定位到alert/confirm/prompt。然后使用text/accept/dismiss/send_keys 按需进行操做。

text 返回alert/confirm/prompt 中的文字信息。
accept 点击确认按钮。
dismiss 点击取消按钮，如果有的话。
send_keys 输入值，这个alert\confirm 没有对话框就不能用了，不然会报错。
</code></pre><p>参考链接：python3 + selenium 之警告和弹窗 - 初新的博客 - CSDN博客  <a href="https://blog.csdn.net/zha6476003/article/details/82686741" target="_blank" rel="noopener">https://blog.csdn.net/zha6476003/article/details/82686741</a></p>
<h1 id="关于无法定位到网页元素的问题"><a href="#关于无法定位到网页元素的问题" class="headerlink" title="关于无法定位到网页元素的问题"></a>关于无法定位到网页元素的问题</h1><h2 id="问题1："><a href="#问题1：" class="headerlink" title="问题1："></a>问题1：</h2><p>无法定位到元素，如果尝试class、id、xpath、selector依旧无法定位，考虑是未切换frame，许多网页都使用iframe内嵌，因此先使用switch_to_frame进行切换。再进行定位。</p>
<h2 id="问题2："><a href="#问题2：" class="headerlink" title="问题2："></a>问题2：</h2><p>如何切换frame：</p>
<pre><code># iframe有name或id值
self.driver.switch_to.frame(&apos;iframe-name-id&apos;)
# iframe没有name或id值
xf = self.driver.find_element_by_xpath(&apos;//iframe[@allowtransparency=&quot;true&quot;]&apos;)
self.driver.switch_to.frame(xf)
# 跳出当前iframe
self.driver.switch_to.parent_frame()
# 返回最外层iframe
self.driver.switch_to.default_content()

参考链接：https://www.cnblogs.com/sgwjj/p/8033076.html
</code></pre><p>其他相关链接：</p>
<pre><code>python3 selenium自动化 frame表单嵌套的切换 - xiezhiming1234的博客 - CSDN博客  https://blog.csdn.net/xiezhiming1234/article/details/82924950

Python+Selenium定位不到元素常见原因及解决办法（报：NoSuchElementException） - 啄木鸟儿 - 博客园  https://www.cnblogs.com/yufeihlf/p/5689042.html
</code></pre><h1 id="selenium：解决页面元素display-none的方法"><a href="#selenium：解决页面元素display-none的方法" class="headerlink" title="selenium：解决页面元素display:none的方法"></a>selenium：解决页面元素display:none的方法</h1><p>文章链接：selenium：解决页面元素display:none的方法 - 老_张 - 博客园  <a href="https://www.cnblogs.com/imyalost/p/8948458.html" target="_blank" rel="noopener">https://www.cnblogs.com/imyalost/p/8948458.html</a></p>
<p>在UI自动化测试中，有时候会遇到页面元素无法定位的问题，包括xpath等方法都无法定位，是因为前端元素被设置为不可见导致。</p>
<p>这篇博客，介绍下如何通过JavaScript修改页面元素属性来定位的方法。</p>
<h2 id="1、具体问题"><a href="#1、具体问题" class="headerlink" title="1、具体问题"></a>1、具体问题</h2><p>常见的页面元素不可见导致的不可定位，都是由于下面的问题：<br><img src="https://i.imgur.com/kERW38S.png" alt=""><br>通过查看相关文档，可以看出display:none方法是设置元素不可见，这就是导致为什么通过定位页面元素无法定位的原因。</p>
<p><img src="https://i.imgur.com/zVjmiRj.png" alt=""></p>
<p>关于display更多的信息，可以看这里：<a href="http://www.w3school.com.cn/jsref/prop_style_display.asp" target="_blank" rel="noopener">http://www.w3school.com.cn/jsref/prop_style_display.asp</a></p>
<h2 id="2、解决方案"><a href="#2、解决方案" class="headerlink" title="2、解决方案"></a>2、解决方案</h2><p>对于这种问题，可以通过JavaScript修改页面元素属性来将元素置位可见，然后通过id、classname等方法去定位，示例代码如下（针对上图所示）：</p>
<pre><code>js = &quot;document.getElementById(\&quot;txtPassword\&quot;).style.display=&apos;block&apos;;&quot;
# 调用js脚本
driver.execute_script(js)
sleep(3)
driver.find_element_by_id(&quot;txtPassword&quot;).send_keys(&quot;123456&quot;)
</code></pre><h3 id="代码解析："><a href="#代码解析：" class="headerlink" title="代码解析："></a>代码解析：</h3><p>首先通过selenium封装好的方法document去找到display元素，document提供以下方法来定位display元素：</p>
<p>getElementById()：返回对指定ID第一个对象的引用</p>
<p>getElementsByName() ：返回带有指定名称的对象集合</p>
<p>getElementsByTagName()：返回带有指定标签名的对象集合</p>
<p><img src="https://i.imgur.com/63IyE8B.png" alt=""><br>关于document更多的信息，可以看这里：<a href="http://www.w3school.com.cn/jsref/dom_obj_document.asp" title="HTML DOM Document 对象" target="_blank" rel="noopener">http://www.w3school.com.cn/jsref/dom_obj_document.asp</a></p>
<p>上面我定义了一个js变量，然后通过getElementById()方法去引用display元素，修改none属性为block属性（作为块级元素显示），然后通过selenium自带的execute_script方法执行脚本。</p>
<p>最后，当元素属性置为可见时，可以通过ID去定位元素。</p>
<p>其实还有一个解决方案：让前端修改display:none为block就好了，但这样的话，带来的变化和安全风险又是需要考虑的问题。</p>
<h1 id="关于上传文件时操作windows弹窗"><a href="#关于上传文件时操作windows弹窗" class="headerlink" title="关于上传文件时操作windows弹窗"></a>关于上传文件时操作windows弹窗</h1><p>selenium是一个相当方便的东西，但是有些功能它也并不能完成，比如上传文件，swf插件的点击操作，和各种不在web中需要在Windows进行相关的操作。</p>
<p>一般来说，上传文件的HTML代码都是使用input type=’file’标签完成的，而这种的上传文件比较好操作，可使用send_Keys方法完成。</p>
<p>相关链接：selenium部分功能（上传文件、swf插件）无法自动化时可使用的方法 - 宋天真的博客 - CSDN博客  <a href="https://blog.csdn.net/songjiaping/article/details/52091136" target="_blank" rel="noopener">https://blog.csdn.net/songjiaping/article/details/52091136</a></p>
<p>百度多种方式，最终定位：使用<strong>Autoit</strong></p>
<p>Autoit官网：<a href="https://www.autoitscript.com/site/" target="_blank" rel="noopener">https://www.autoitscript.com/site/</a></p>
<p>下载地址： AutoIt Downloads - AutoIt  <a href="https://www.autoitscript.com/site/autoit/downloads/" target="_blank" rel="noopener">https://www.autoitscript.com/site/autoit/downloads/</a></p>
<p><img src="https://i.imgur.com/NGbaTmv.png" alt=""></p>
<p>具体教程：Selenium 自动化测试不同类型上传文件实用方法总结 - 简书  <a href="https://www.jianshu.com/p/f25ff87a8f17" target="_blank" rel="noopener">https://www.jianshu.com/p/f25ff87a8f17</a></p>
<p>python3 + selenium 之文件上传下载 - 初新的博客 - CSDN博客  <a href="https://blog.csdn.net/zha6476003/article/details/82686821" target="_blank" rel="noopener">https://blog.csdn.net/zha6476003/article/details/82686821</a></p>
<p>Python selenium —— 文件下载，不弹出窗口，直接下载到指定路径 - 灰蓝 - CSDN博客  <a href="https://blog.csdn.net/huilan_same/article/details/52789954?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io" target="_blank" rel="noopener">https://blog.csdn.net/huilan_same/article/details/52789954?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io</a></p>
<h1 id="下载文件"><a href="#下载文件" class="headerlink" title="下载文件"></a>下载文件</h1><blockquote>
<p>with open（）as f语句：</p>
<p>python文件读写,以后就用with open语句 - 有梦就要去实现他 - 博客园  <a href="https://www.cnblogs.com/ymjyqsx/p/6554817.html" target="_blank" rel="noopener">https://www.cnblogs.com/ymjyqsx/p/6554817.html</a></p>
</blockquote>
<h2 id="1、对于Firefox下载文件"><a href="#1、对于Firefox下载文件" class="headerlink" title="1、对于Firefox下载文件"></a>1、对于Firefox下载文件</h2><p>对于Firefox，需要我们设置其Profile：</p>
<pre><code>browser.download.dir：指定下载路径
browser.download.folderList：设置成 2 表示使用自定义下载路径；设置成 0 表示下载到桌面；设置成 1 表示下载到默认路径
browser.download.manager.showWhenStarting：在开始下载时是否显示下载管理器
browser.helperApps.neverAsk.saveToDisk：对所给出文件类型不再弹出框进行询问
</code></pre><p>Firefox需要针对每种文件类型进行设置，这里需要我们查询对应文件的MIME类型，可以用以下链接进行查询：MIME 参考手册  <a href="http://www.w3school.com.cn/media/media_mimeref.asp" target="_blank" rel="noopener">http://www.w3school.com.cn/media/media_mimeref.asp</a></p>
<h2 id="2、Chrome文件下载"><a href="#2、Chrome文件下载" class="headerlink" title="2、Chrome文件下载"></a>2、Chrome文件下载</h2><p>Chrome浏览器类似，设置其options：</p>
<pre><code>download.default_directory：设置下载路径
profile.default_content_settings.popups：设置为 0 禁止弹出窗口
</code></pre><p>相关链接：Python selenium —— 文件下载，不弹出窗口，直接下载到指定路径 - 灰蓝 - CSDN博客  <a href="https://blog.csdn.net/huilan_same/article/details/52789954?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io" target="_blank" rel="noopener">https://blog.csdn.net/huilan_same/article/details/52789954?hmsr=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io</a></p>
<p>selenium部分功能（上传文件、swf插件）无法自动化时可使用的方法 - 宋天真的博客 - CSDN博客  <a href="https://blog.csdn.net/songjiaping/article/details/52091136" target="_blank" rel="noopener">https://blog.csdn.net/songjiaping/article/details/52091136</a></p>
<h1 id="Request-模块"><a href="#Request-模块" class="headerlink" title="Request 模块"></a>Request 模块</h1><p>参考链接：python3爬虫（一）requests库的学习 - saucerman的世界 - CSDN博客  <a href="https://blog.csdn.net/gyq1998/article/details/78583841" target="_blank" rel="noopener">https://blog.csdn.net/gyq1998/article/details/78583841</a></p>
<h2 id="1、Requests库的七个主要方法"><a href="#1、Requests库的七个主要方法" class="headerlink" title="1、Requests库的七个主要方法"></a>1、Requests库的七个主要方法</h2><p><img src="https://i.imgur.com/AFprYiP.png" alt=""></p>
<h3 id="1-requests-request"><a href="#1-requests-request" class="headerlink" title="(1) requests.request()"></a>(1) requests.request()</h3><p>这个方法是我们平时最常用的方法之一，通过这个方法我们可以了解到其他的方法，所以我们详细介绍这个方法。<br>具体参数是：</p>
<pre><code>r=requests.request(url,params,**kwargs)

url: 需要爬取的网站地址。
params: 翻译过来就是参数， url中的额外参数，字典或者字节流格式，可选。
 **kwargs : 12个控制访问的参数
</code></pre><p>**kwargs有以下的参数，对于requests.get,其第一个参数被提出来了。</p>
<pre><code>params：字典或字节序列， 作为参数增加到url中,使用这个参数可以把一些键值对以?key1=value1&amp;key2=value2的模式增加到url中 
例如：kv = {‘key1: ’ values’, ‘key2’: ‘values’} 
r = requests.request(‘GET’, ‘http:www.python123.io/ws’, params=kw)

data：字典，字节序或文件对象，重点作为向服务器提供或提交资源是提交，，作为request的内容，与params不同的是，data提交的数据并不放在url链接里， 而是放在url链接对应位置的地方作为数据来存储。，它也可以接受一个字符串对象。

json：json格式的数据， json合适在相关的html，http相关的web开发中非常常见， 也是http最经常使用的数据格式， 他是作为内容部分可以向服务器提交。 
例如：kv = {”key1’: ‘value1’} 
r = requests.request(‘POST’, ‘http://python123.io/ws‘, json=kv)

headers：字典是http的相关语，对应了向某个url访问时所发起的http的头i字段， 可以用这个字段来定义http的访问的http头，可以用来模拟任何我们想模拟的浏览器来对url发起访问。 
例子： hd = {‘user-agent’: ‘Chrome/10’} 
r = requests.request(‘POST’, ‘http://python123.io/ws‘, headers=hd)

cookies：字典或CookieJar，指的是从http中解析cookie

auth：元组，用来支持http认证功能

files：字典， 是用来向服务器传输文件时使用的字段。 
例子：fs = {‘files’: open(‘data.txt’, ‘rb’)} 
r = requests.request(‘POST’, ‘http://python123.io/ws‘, files=fs)

timeout: 用于设定超时时间， 单位为秒，当发起一个get请求时可以设置一个timeout时间， 如果在timeout时间内请求内容没有返回， 将产生一个timeout的异常。

proxies：字典， 用来设置访问代理服务器。

allow_redirects: 开关， 表示是否允许对url进行重定向， 默认为True。

stream: 开关， 指是否对获取内容进行立即下载， 默认为True。

verify：开关， 用于认证SSL证书， 默认为True。

cert： 用于设置保存本地SSL证书路径

这句代码是构造一个服务器请求request，返回一个包含服务器资源的response对象。
</code></pre><h3 id="（2）requests-get"><a href="#（2）requests-get" class="headerlink" title="（2）requests.get()"></a>（2）requests.get()</h3><p>response对象的属性：</p>
<p><img src="https://i.imgur.com/Fh9ynNp.png" alt=""><br>补充：</p>
<pre><code>r.status_code #响应状态码

r.raw #返回原始响应体，也就是 urllib 的 response 对象，使用 r.raw.read() 读取

r.content #字节方式的响应体，会自动为你解码 gzip 和 deflate 压缩

r.text #字符串方式的响应体，会自动根据响应头部的字符编码进行解码

r.headers #以字典对象存储服务器响应头，但是这个字典比较特殊，字典键不区分大小写，若键不存在则返回None

特殊方法：
r.json()       #Requests中内置的JSON解码器
r.raise_for_status() #失败请求(非200响应)抛出异常
</code></pre><p>（参考链接：Python3 API 第三方库 requests 详解 - 屁股决定脑袋的专栏 - CSDN博客  <a href="https://blog.csdn.net/yilovexing/article/details/54928769）" target="_blank" rel="noopener">https://blog.csdn.net/yilovexing/article/details/54928769）</a></p>
<p>举例</p>
<pre><code>&gt;&gt;&gt; import requests
&gt;&gt;&gt; r=requests.get(&quot;http://www.baidu.com&quot;)
&gt;&gt;&gt; r.status_code
200
&gt;&gt;&gt;  r.encoding
&apos;ISO-8859-1&apos;
&gt;&gt;&gt; r.apparent_encoding
&apos;utf-8&apos;
&gt;&gt;&gt; r.text
&apos;&lt;!DOCTYPE html&gt;\r\n&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;ipt&gt; &lt;a href=//www.baidu.com/more/ name=tj_briicon class=bri style=&quot;display: block;&quot;&gt;æ\x9b´å¤\x9aäº§å\x93\x81&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id=ftCon&gt; &lt;div id=ftConw&gt; &lt;p id=lh&gt; &lt;a com/ class=cp-feedback&gt;æ\x84\x8fè§\x81å\x8f\x8dé¦\x88&lt;/a&gt;&amp;nbsp;äº¬ICPè¯\x81030173å\x8f·&amp;nbsp; &lt;img src=//www.baidu.com/img/gs.gif&gt; &lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;\r\n&apos;
&gt;&gt;&gt; r.encoding=&apos;utf-8&apos;
&gt;&gt;&gt; r.text
（以上r.text内容过长，自行删除了部分，看出编码效果即可）
</code></pre><p>若想在url中添加参数有两种方式：</p>
<p>a. 直接添加</p>
<pre><code>r = requests.get(url+参数)
</code></pre><p>b. 通过params参数添加</p>
<pre><code>import requests
data = {&quot;name&quot;:&quot;Infi-chu&quot;,&quot;age&quot;:&quot;23&quot;}
r = requests.get(url,params=data)
</code></pre><p>网页的返回类型是str类型，是JSON格式的，我们可以直接调用 json()方法</p>
<p>若返回结果不是JSON格式，便会出现解析错误，抛出 json.decode.JSONDecodeError异常</p>
<ul>
<li>抓取网页</li>
</ul>
<p>可使用正则表达式和headers。</p>
<ul>
<li>抓取二进制数据</li>
</ul>
<p>图片、音频、视频等文件本质上都是二进制码组成的。</p>
<p>抓取GitHub图标：</p>
<pre><code>import requests
r = requests.get(&quot;http://github.com/favicon.ico&quot;)
print(r.text)
print(r.content)
# 保存图片
with open(&apos;favicon.ico&apos;,&apos;wb&apos;) as f:
f.write(r.content)
</code></pre><ul>
<li>添加headers</li>
</ul>
<p>在爬取知乎时必须在User-Agent中加入信息，否则不能爬取，会被拦截</p>
<h3 id="requests库的异常"><a href="#requests库的异常" class="headerlink" title="requests库的异常"></a>requests库的异常</h3><p>注意requests库有时会产生异常，比如网络连接错误、http错误异常、重定向异常、请求url超时异常等等。所以我们需要判断r.status_codes是否是200，在这里我们怎么样去捕捉异常呢？</p>
<p>这里我们可以利用r.raise_for_status() 语句去捕捉异常，该语句在方法内部判断r.status_code是否等于200，如果不等于，则抛出异常。</p>
<p>于是在这里我们有一个爬取网页的通用代码框架：</p>
<pre><code>try:
    r=requests.get(url,timeout=30)#请求超时时间为30秒
    r.raise_for_status()#如果状态不是200，则引发异常
    r.encoding=r.apparent_encoding #配置编码
    return r.text
except:
    return&quot;产生异常&quot;
</code></pre><h3 id="3-request-head"><a href="#3-request-head" class="headerlink" title="(3) request.head()"></a>(3) request.head()</h3><p>看代码：</p>
<pre><code>r=requests.head(&quot;http://www.baidu.com&quot;)
r.headers
{&apos;Cache-Control&apos;: &apos;private, no-cache, no-store, proxy-revalidate, no-transform&apos;, &apos;Connection&apos;: &apos;Keep-Alive&apos;, &apos;Content-Encoding&apos;: &apos;gzip&apos;, &apos;Content-Type&apos;: &apos;text/html&apos;, &apos;Date&apos;: &apos;Wed, 31 Oct 2018 06:43:49 GMT&apos;, &apos;Last-Modified&apos;: &apos;Mon, 13 Jun 2016 02:50:36 GMT&apos;, &apos;Pragma&apos;: &apos;no-cache&apos;, &apos;Server&apos;: &apos;bfe/1.0.8.18&apos;}
r.text
&apos;&apos;
</code></pre><h3 id="（4）requests-post"><a href="#（4）requests-post" class="headerlink" title="（4）requests.post()"></a>（4）requests.post()</h3><pre><code>improt requests
data = {&apos;name&apos;:&apos;Infi-chu&apos;,&apos;age&apos;=&apos;23&apos;}
r = requests.post(&apos;http://www.baidu.com&apos;,data=data)
</code></pre><p>成功后会在form中看到所提交的数据（F12查看）</p>
<p><strong>1、向url post一个字典：</strong></p>
<pre><code>payload={&quot;key1&quot;:&quot;value1&quot;,&quot;key2&quot;:&quot;value2&quot;}
r=requests.post(&quot;http://httpbin.org/post&quot;,data=payload)
print(r.text)
{
&quot;args&quot;: {}, 
&quot;data&quot;: &quot;&quot;, 
&quot;form&quot;: {
&quot;key1&quot;: &quot;value1&quot;, 
&quot;key2&quot;: &quot;value2&quot;
}, 
&quot;headers&quot;: {
&quot;Accept&quot;: &quot;*/*&quot;, 
&quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, 
&quot;Connection&quot;: &quot;close&quot;, 
&quot;Content-Length&quot;: &quot;23&quot;, 
&quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;, 
&quot;Host&quot;: &quot;httpbin.org&quot;, 
&quot;User-Agent&quot;: &quot;python-requests/2.18.4&quot;
}, 
&quot;json&quot;: null, 
&quot;origin&quot;: &quot;218.197.153.150&quot;, 
&quot;url&quot;: &quot;http://httpbin.org/post&quot;
}
</code></pre><p><strong>2、向url post 一个字符串，自动编码为data</strong></p>
<pre><code>r=requests.post(&quot;http://httpbin.org/post&quot;,data=&apos;helloworld&apos;)
print(r.text)
{
&quot;args&quot;: {}, 
&quot;data&quot;: &quot;helloworld&quot;, 
&quot;files&quot;: {}, 
&quot;form&quot;: {}, 
&quot;headers&quot;: {
&quot;Accept&quot;: &quot;*/*&quot;, 
&quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, 
&quot;Connection&quot;: &quot;close&quot;, 
&quot;Content-Length&quot;: &quot;10&quot;, 
&quot;Host&quot;: &quot;httpbin.org&quot;, 
&quot;User-Agent&quot;: &quot;python-requests/2.18.4&quot;
}, 
&quot;json&quot;: null, 
&quot;origin&quot;: &quot;218.197.153.150&quot;, 
&quot;url&quot;: &quot;http://httpbin.org/post&quot;
}
</code></pre><ul>
<li>响应</li>
</ul>
<p>发送数据后，得到的就是响应，我们使用text和content获取了内容，下面是另外的信息：</p>
<pre><code>&gt;&gt;&gt; import requests
&gt;&gt;&gt; r = requests.get(&apos;http://www.baidu.com&apos;)
&gt;&gt;&gt; print(type(r.status_code),r.status_code)
&lt;class &apos;int&apos;&gt; 200
&gt;&gt;&gt; print(type(r.headers),r.headers)
&lt;class &apos;requests.structures.CaseInsensitiveDict&apos;&gt; {&apos;Cache-Control&apos;: &apos;private, no-cache, no-store, proxy-revalidate, no-transform&apos;, &apos;Connection&apos;: &apos;Keep-Alive&apos;, &apos;Content-Encoding&apos;: &apos;gzip&apos;, &apos;Content-Type&apos;: &apos;text/html&apos;, &apos;Date&apos;: &apos;Tue, 06 Nov 2018 06:44:52 GMT&apos;, &apos;Last-Modified&apos;: &apos;Mon, 23 Jan 2017 13:28:24 GMT&apos;, &apos;Pragma&apos;: &apos;no-cache&apos;, &apos;Server&apos;: &apos;bfe/1.0.8.18&apos;, &apos;Set-Cookie&apos;: &apos;BDORZ=27315; max-age=86400; domain=.baidu.com; path=/&apos;, &apos;Transfer-Encoding&apos;: &apos;chunked&apos;}
&gt;&gt;&gt; print(type(r.cookies),r.cookies)
&lt;class &apos;requests.cookies.RequestsCookieJar&apos;&gt; &lt;RequestsCookieJar[&lt;Cookie BDORZ=27315 for .baidu.com/&gt;]&gt;
&gt;&gt;&gt; print(type(r.history),r.history)
&lt;class &apos;list&apos;&gt; []
&gt;&gt;&gt; print(type(r.url),r.url)
&lt;class &apos;str&apos;&gt; http://www.baidu.com/
</code></pre><p>　headers 属性返回 CaseInsensitiveDict 类型</p>
<p>　cookies 属性返回 RequestsCookieJar 类型</p>
<p>其他：</p>
<pre><code>r.status_code #响应状态码
r.raw #返回原始响应体，也就是 urllib 的 response 对象，使用 r.raw.read() 读取
r.content #字节方式的响应体，会自动为你解码 gzip 和 deflate 压缩
r.text #字符串方式的响应体，会自动根据响应头部的字符编码进行解码
r.headers #以字典对象存储服务器响应头，但是这个字典比较特殊，字典键不区分大小写，若键不存在则返回None
#*特殊方法*#
r.json() #Requests中内置的JSON解码器
r.raise_for_status() #失败请求(非200响应)抛出异常
</code></pre><h3 id="（5）requests-put"><a href="#（5）requests-put" class="headerlink" title="（5）requests.put()"></a>（5）requests.put()</h3><pre><code>payload={&quot;key1&quot;:&quot;value1&quot;,&quot;key2&quot;:&quot;value2&quot;}
r=requests.put(&quot;http://httpbin.org/put&quot;,data=payload)
print(r.text)
{
&quot;args&quot;: {}, 
&quot;data&quot;: &quot;&quot;, 
&quot;files&quot;: {}, 
&quot;form&quot;: {
&quot;key1&quot;: &quot;value1&quot;, 
&quot;key2&quot;: &quot;value2&quot;
}, 
&quot;headers&quot;: {
&quot;Accept&quot;: &quot;*/*&quot;, 
&quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, 
&quot;Connection&quot;: &quot;close&quot;, 
&quot;Content-Length&quot;: &quot;23&quot;, 
&quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;, 
&quot;Host&quot;: &quot;httpbin.org&quot;, 
&quot;User-Agent&quot;: &quot;python-requests/2.18.4&quot;
}, 
&quot;json&quot;: null, 
&quot;origin&quot;: &quot;218.197.153.150&quot;, 
&quot;url&quot;: &quot;http://httpbin.org/put&quot;
</code></pre><h3 id="（6）requests-patch"><a href="#（6）requests-patch" class="headerlink" title="（6）requests.patch()"></a>（6）requests.patch()</h3><p>requests.patch和request.put类似。 </p>
<p>两者不同的是：<br>当我们用patch时仅需要提交需要修改的字段。<br>而用put时，必须将20个字段一起提交到url，未提交字段将会被删除。<br>patch的好处是：节省网络带宽。</p>
<h3 id="（7）requests-request"><a href="#（7）requests-request" class="headerlink" title="（7）requests.request()"></a>（7）requests.request()</h3><p>requests.request(）支持其他所有的方法。</p>
<pre><code>requests.request(method，url,**kwargs)
method: “GET”、”HEAD”、”POST”、”PUT”、”PATCH”等等
url: 请求的网址
**kwargs: 控制访问的参数
</code></pre><p>requests模块的使用实例（见链接：<a href="https://blog.csdn.net/gyq1998/article/details/78583841）" target="_blank" rel="noopener">https://blog.csdn.net/gyq1998/article/details/78583841）</a></p>
<p>Python3 API 第三方库 requests 详解 - 屁股决定脑袋的专栏 - CSDN博客  <a href="https://blog.csdn.net/yilovexing/article/details/54928769" target="_blank" rel="noopener">https://blog.csdn.net/yilovexing/article/details/54928769</a></p>
<h2 id="2-requests高级用法"><a href="#2-requests高级用法" class="headerlink" title="2.requests高级用法"></a>2.requests高级用法</h2><h3 id="1-文件上传"><a href="#1-文件上传" class="headerlink" title="1.文件上传"></a>1.文件上传</h3><pre><code>import requests
f = {&apos;file&apos;:open(&apos;favicon.ico&apos;,&apos;rb&apos;)}
r = requests.post(url,files=f)
print(r.text)
</code></pre><h3 id="2-Cookies"><a href="#2-Cookies" class="headerlink" title="2.Cookies"></a>2.Cookies</h3><pre><code>import requests
r = requests.get(url)
print(r.cookies)
for k,v in r.cookies.items():
    print(k+&quot;=&quot;+v)
</code></pre><h3 id="3-会话维持"><a href="#3-会话维持" class="headerlink" title="3.会话维持"></a>3.会话维持</h3><p>使用Session对象</p>
<pre><code>import requests
s = requests.Session()
s.get(&apos;http://httpbin.org/cookies/set/number/123456789&apos;)
r = s.get(&apos;http://httpbin.org/cookies&apos;)
print(r.text)
</code></pre><h3 id="4-SSL证书认证"><a href="#4-SSL证书认证" class="headerlink" title="4.SSL证书认证"></a>4.SSL证书认证</h3><p>requests提供了证书验证的功能，使用verify参数控制是否检查此证书，默认是True，会自动验证</p>
<h3 id="5-代理设置"><a href="#5-代理设置" class="headerlink" title="5.代理设置"></a>5.代理设置</h3><p>对于某些网站，在测试的时候请求几次，能正常获取信息，但是一旦大规模爬取，可能会出现验证码或直接封掉IP，导致一段时间内无法访问</p>
<p>代理设置：</p>
<pre><code>import requests
proxy = {&apos;http&apos;:&apos;http://ip:port&apos;,&apos;https&apos;:&apos;https://ip:port&apos;}
requests.get(&apos;https://www.taobao.com&apos;,proxies=proxy)
</code></pre><h3 id="6-超时设置"><a href="#6-超时设置" class="headerlink" title="6.超时设置"></a>6.超时设置</h3><pre><code>import requests
r = requests.get(&apos;https://www.taobao.com&apos;,timeout=1)
print(r.status_code)
</code></pre><h3 id="7-身份认证"><a href="#7-身份认证" class="headerlink" title="7.身份认证"></a>7.身份认证</h3><pre><code>import requests
from requests.auth import HTTPBasicAuth
r = requests.get(url,auth=HTTPBasicAuth(&apos;username&apos;,&apos;password&apos;))
print(r.status_code)

# 可简写为
r = requests.get(url,auth=(&apos;username&apos;,&apos;password&apos;))
print(r.status_code)
# 也提供了OAuth认证，使用 pip3 install requests_oauthlib
</code></pre><h3 id="8-Prepared-Request"><a href="#8-Prepared-Request" class="headerlink" title="8.Prepared Request"></a>8.Prepared Request</h3><p>将请求表示为数据结构，这个数据结构叫Prepared Request</p>
<p>（链接：Python3爬虫（四）请求库的使用requests - Infi_chu - 博客园  <a href="https://www.cnblogs.com/Infi-chu/p/8961065.html）" target="_blank" rel="noopener">https://www.cnblogs.com/Infi-chu/p/8961065.html）</a></p>
<h1 id="执行JavaScript"><a href="#执行JavaScript" class="headerlink" title="执行JavaScript"></a>执行JavaScript</h1><h3 id="1-Example-1进入浏览器之后，隐藏文字和按钮，及弹出一个alert弹框"><a href="#1-Example-1进入浏览器之后，隐藏文字和按钮，及弹出一个alert弹框" class="headerlink" title="1.Example 1进入浏览器之后，隐藏文字和按钮，及弹出一个alert弹框"></a>1.Example 1进入浏览器之后，隐藏文字和按钮，及弹出一个alert弹框</h3><pre><code>import time,os

driver = webdriver.Chrome()
file_path = &quot;file:///&quot; + os.path.abspath(&apos;html/js.html&apos;)
driver.get(file_path)

driver.execute_script(&apos;$(&quot;#tooltip&quot;).fadeOut();&apos;)
time.sleep(5)

button = driver.find_element_by_class_name(&apos;btn&apos;)
driver.execute_script(&apos;$(arguments[0]).fadeOut()&apos;, button)
time.sleep(5)

driver.get(&apos;https://www.baidu.com&apos;)
time.sleep(2)

driver.execute_script(&quot;alert(&apos;This is an alert board&apos;);&quot;)
time.sleep(5)
driver.quit()
</code></pre><h3 id="2-Example-2执行JS脚本来控制浏览器竖向滚动条"><a href="#2-Example-2执行JS脚本来控制浏览器竖向滚动条" class="headerlink" title="2.Example 2执行JS脚本来控制浏览器竖向滚动条"></a>2.Example 2执行JS脚本来控制浏览器竖向滚动条</h3><p>一般用到操作滚动条的会两个场景：</p>
<p>  1）注册时的法律条文的阅读，判断用户是否阅读完成的标准是：滚动条是否拉到最下方。<br>  2）要操作的页面元素不在视觉范围，无法进行操作，需要拖动滚动条</p>
<p>用于标识滚动条位置的代码</p>
<pre><code>&lt;body onload= &quot;document.body.scrollTop=0 &quot;&gt;
&lt;body onload= &quot;document.body.scrollTop=100000 &quot;&gt;
</code></pre><p>如果滚动条在最上方的话，scrollTop=0 ，那么要想使用滚动条在最可下方，可以scrollTop=100000 ，这样就可以使滚动条在最下方。</p>
<pre><code>from selenium import webdriver
import time

driver = webdriver.Chrome()
driver.get(&apos;https://www.baidu.com&apos;)

driver.find_element_by_id(&apos;kw&apos;).send_keys(&quot;selenium&quot;)
driver.find_element_by_id(&apos;su&apos;).click()
time.sleep(3)
#driver.set_window_size(749, 560)
#js = &quot;var q=document.documentElement.scrollTop=100000&quot;
#driver.execute_script(js)
driver.get(&apos;https://tieba.baidu.com/index.html&apos;)
time.sleep(2)

ele = driver.find_element_by_link_text(&quot;人文自然&quot;)
#driver.execute_script(&quot;arguments[0].scrollIntoView();&quot;,ele) #移动到元素element对象的“顶端”与当前窗口的“顶部”对齐
#driver.execute_script(&quot;scroll(0,2400)&quot;) #大概的拖动
#driver.execute_script(&quot;arguments[0].scrollIntoView(false);&quot;,ele) #移动到元素element对象的“底端”与当前窗口的“底部”对齐
driver.execute_script(&quot;window.scrollTo(0,document.body.scrollHeight)&quot;) #移动到页面最底部

time.sleep(3)

driver.quit()
</code></pre><p>参考链接：Python_selenium之执行JavaScript - Rita_LJ - 博客园  <a href="https://www.cnblogs.com/Rita-LJ/p/7884995.html" target="_blank" rel="noopener">https://www.cnblogs.com/Rita-LJ/p/7884995.html</a></p>
<h1 id="Cookies操作"><a href="#Cookies操作" class="headerlink" title="Cookies操作"></a>Cookies操作</h1><p>链接：python3+selenium入门13-操作cookie - 梦忆安凉 - 博客园  <a href="https://www.cnblogs.com/myal/p/9389942.html" target="_blank" rel="noopener">https://www.cnblogs.com/myal/p/9389942.html</a></p>
<h1 id="获取验证码-识别图片文字"><a href="#获取验证码-识别图片文字" class="headerlink" title="获取验证码-识别图片文字"></a>获取验证码-识别图片文字</h1><p>相关链接：Python3.6使用tesseract-ocr的正确姿势 - No.96 - CSDN博客  <a href="https://blog.csdn.net/qq_14998713/article/details/78824859" target="_blank" rel="noopener">https://blog.csdn.net/qq_14998713/article/details/78824859</a></p>
<h2 id="安装："><a href="#安装：" class="headerlink" title="安装："></a>安装：</h2><p>Tesseract：开源的OCR识别引擎，初期Tesseract引擎由HP实验室研发，后来贡献给了开源软件业，后经由Google进行改进，消除bug，优化，重新发布。</p>
<h3 id="1、tesseract-orc"><a href="#1、tesseract-orc" class="headerlink" title="1、tesseract-orc"></a>1、tesseract-orc</h3><p>环境：</p>
<pre><code>python 3.6.5
pip 9.0.3
tesseract-ocr-setup-3.05.00dev.exe
Windows7
</code></pre><p>链接：<a href="https://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-setup-3.05.00dev.exe" target="_blank" rel="noopener">https://digi.bib.uni-mannheim.de/tesseract/tesseract-ocr-setup-3.05.00dev.exe</a></p>
<h3 id="2、pytesseract"><a href="#2、pytesseract" class="headerlink" title="2、pytesseract"></a>2、pytesseract</h3><pre><code>pip install pytesseract
</code></pre><h2 id="配置环境变量："><a href="#配置环境变量：" class="headerlink" title="配置环境变量："></a>配置环境变量：</h2><p>默认情况下tesseract-orc是不被添加到系统的path路径的，这样在使用的时候发生FileNotFoundError: [WinError 2] 系统找不到指定的文件错误。</p>
<p>解决方法: </p>
<pre><code>将 C:\Program Files (x86)\Tesseract-OCR添加到系统路径（路径因安装过程而异） 
</code></pre><p>设置训练集的位置</p>
<pre><code>下载的默认训练集也没有添加到系统路径,会报错pytesseract.pytesseract.TesseractError: (1, &apos;Error opening data file \\Program Files (x86)\\Tesseract-OCR\\tessdata/chi_sim.traineddata&apos;)
</code></pre><p>解决方法：<br>设置环境变量 TESSDATA_PREFIX<br>C:\Program Files (x86)\Tesseract-OCR\tessdata</p>
<p>实例：</p>
<pre><code>import pytesseract
from PIL import Image

image = Image.open(&apos;test.png&apos;)
code = pytesseract.image_to_string(image)
print(code)
</code></pre><p>更多链接： python+tesseract验证码识别的一点小心得 - 菲菲菲菲菲常新的新手 - 博客园  <a href="https://www.cnblogs.com/lgh344902118/p/6672706.html" target="_blank" rel="noopener">https://www.cnblogs.com/lgh344902118/p/6672706.html</a></p>
<p>Python 3.6 版本 Pytesseract 图像验证码识别 PyCharm 报错FileNotFoundError - 流浪的喵的博客 - CSDN博客  <a href="https://blog.csdn.net/u010134642/article/details/78747630" target="_blank" rel="noopener">https://blog.csdn.net/u010134642/article/details/78747630</a></p>
<p>Tesseract-OCR入门使用（1）-安装包获取和命令行调用 - 我不是校长的博客 - CSDN博客  <a href="https://blog.csdn.net/u012566751/article/details/54094692" target="_blank" rel="noopener">https://blog.csdn.net/u012566751/article/details/54094692</a></p>
<p>python pip ,安装，卸载，查看等命令，不同版本 - x.cube - 博客园  <a href="https://www.cnblogs.com/xiexiaoxiao/p/7147920.html" target="_blank" rel="noopener">https://www.cnblogs.com/xiexiaoxiao/p/7147920.html</a></p>
<h1 id="验证码处理"><a href="#验证码处理" class="headerlink" title="验证码处理"></a>验证码处理</h1><p>参考链接：Python3爬虫（十四） 验证码处理 - Infi_chu - 博客园  <a href="https://www.cnblogs.com/Infi-chu/p/8991810.html" target="_blank" rel="noopener">https://www.cnblogs.com/Infi-chu/p/8991810.html</a></p>
<h2 id="简单爬取网页图片"><a href="#简单爬取网页图片" class="headerlink" title="简单爬取网页图片"></a>简单爬取网页图片</h2><p>链接：Python3简单爬虫抓取网页图片 - 孙苗青 - 博客园  <a href="https://www.cnblogs.com/smq772340208/p/6927063.html" target="_blank" rel="noopener">https://www.cnblogs.com/smq772340208/p/6927063.html</a></p>
<pre><code>import urllib.request
import re
import os
import urllib
#根据给定的网址来获取网页详细信息，得到的html就是网页的源代码  
def getHtml(url):
    page = urllib.request.urlopen(url)
    html = page.read()
    return html.decode(&apos;UTF-8&apos;)

def getImg(html):
    reg = r&apos;src=&quot;(.+?\.jpg)&quot; pic_ext&apos;
    imgre = re.compile(reg)
    imglist = imgre.findall(html)#表示在整个网页中过滤出所有图片的地址，放在imglist中
    x = 0
    path = &apos;D:\\test&apos;  
   # 将图片保存到D:\\test文件夹中，如果没有test文件夹则创建
    if not os.path.isdir(path):  
        os.makedirs(path)  
    paths = path+&apos;\\&apos;      #保存在test路径下  

    for imgurl in imglist:  
        urllib.request.urlretrieve(imgurl,&apos;{}{}.jpg&apos;.format(paths,x))  #打开imglist中保存的图片网址，并下载图片保存在本地，format格式化字符串 
        x = x + 1  
    return imglist
html = getHtml(&quot;http://tieba.baidu.com/p/2460150866&quot;)#获取该网址网页详细信息，得到的html就是网页的源代码  
print (getImg(html)) #从网页源代码中分析并下载保存图片
</code></pre><p>其他链接：使用python3进行优雅的爬虫（一）爬取图片 - 简书  <a href="https://www.jianshu.com/p/696922f268df" target="_blank" rel="noopener">https://www.jianshu.com/p/696922f268df</a></p>
<p><em>附注： src=”(.+?.jpg)” pic_ext的含义</em></p>
<pre><code>src=&quot; #匹配src=&quot;
(.+?\.jpg)
# 括号表示分组，将括号的内容捕获到分组当中
# .+表示匹配至少一个任意字符，问号?表示懒惰匹配，也就是匹配尽可能少的字符串。
# .+?\.jpg合起来表示尽可能少匹配字符的匹配到.jpg，避免匹配范围超出src的范围
# 这个括号也就可以匹配网页中图片的url了
&quot; pic_ext #匹配&quot; pic_ext
</code></pre><p>截图例：<br><img src="https://i.imgur.com/On4Z65E.png" alt=""></p>
<h3 id="urllib和requests区别："><a href="#urllib和requests区别：" class="headerlink" title="urllib和requests区别："></a>urllib和requests区别：</h3><p>（python3 urllib和requests模块 - 毛斯钢 - 博客园  <a href="https://www.cnblogs.com/znyyy/p/7868511.html）" target="_blank" rel="noopener">https://www.cnblogs.com/znyyy/p/7868511.html）</a></p>
<p>（requests和urllib.request实现对比 - fs_eagle的博客 - CSDN博客  <a href="https://blog.csdn.net/fs_eagle/article/details/79387343）" target="_blank" rel="noopener">https://blog.csdn.net/fs_eagle/article/details/79387343）</a></p>
<h2 id="扩展-re-模块："><a href="#扩展-re-模块：" class="headerlink" title="扩展- re 模块："></a>扩展- re 模块：</h2><h3 id="1、模块总结"><a href="#1、模块总结" class="headerlink" title="1、模块总结"></a>1、模块总结</h3><p>（python3 re模块 - z寒江雪 - 博客园  <a href="https://www.cnblogs.com/wenwei-blog/p/7216102.html）" target="_blank" rel="noopener">https://www.cnblogs.com/wenwei-blog/p/7216102.html）</a></p>
<h3 id="2、re-compile模块"><a href="#2、re-compile模块" class="headerlink" title="2、re.compile模块"></a>2、re.compile模块</h3><p>re模块中包含一个重要函数是compile(pattern [, flags]) ，该函数根据包含的正则表达式的字符串创建模式对象。可以实现更有效率的匹配。在直接使用字符串表示的正则表达式进行search,match和findall操作时，python会将字符串转换为正则表达式对象。而使用compile完成一次转换之后，在每次使用模式的时候就不用重复转换。当然，使用re.compile()函数进行转换后，re.search(pattern, string)的调用方式就转换为 pattern.search(string)的调用方式。</p>
<p>其中，后一种调用方式中，pattern是用compile创建的模式对象。</p>
<pre><code>import re
some_text = &apos;a,b,,,,c d&apos;
reObj = re.compile(&apos;[, ]+&apos;)
reObj.split(some_text)
[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;]
</code></pre><p>在进行search,match等操作前不适用compile函数，会导致重复使用模式时，需要对模式进行重复的转换。降低匹配速度。而此种方法的调用方式，更为直观。如下:</p>
<pre><code>import re
some_text = &apos;a,b,,,,c d&apos;
re.split(&apos;[, ]+&apos;,some_text)
[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;]
</code></pre><p>（python 中的 re.compile 函数 - 王振璇 - 博客园  <a href="https://www.cnblogs.com/nomorewzx/p/4203829.html）" target="_blank" rel="noopener">https://www.cnblogs.com/nomorewzx/p/4203829.html）</a></p>
<p>定义： </p>
<p>compile(pattern[,flags] ) 根据包含正则表达式的字符串创建模式对象。</p>
<pre><code>&gt;&gt;&gt;help(re.compile)
    Help on function compile in module re:

    compile(pattern, flags=0)
    Compile a regular expression pattern, returning a pattern object.
</code></pre><p>通过help可以看到compile方法的介绍，返回一个pattern对象，但是却没有对第二个参数flags进行介绍。第二个参数flags是匹配模式，可以使用按位或’|’表示同时生效，也可以在正则表达式字符串中指定。Pattern对象是不能直接实例化的，只能通过compile方法得到。匹配模式有： </p>
<p>1).re.I(re.IGNORECASE): 忽略大小写 </p>
<p>2).re.M(MULTILINE): 多行模式，改变’^’和’$’的行为 </p>
<p>3).re.S(DOTALL): 点任意匹配模式，改变’.’的行为 </p>
<p>4).re.L(LOCALE): 使预定字符类 \w \W \b \B \s \S 取决于当前区域设定 </p>
<p>5).re.U(UNICODE): 使预定字符类 \w \W \b \B \s \S \d \D 取决于unicode定义的字符属性</p>
<p>6).re.X(VERBOSE): 详细模式。这个模式下正则表达式可以是多行，忽略空白字符，并可以加入注释</p>
<p>(链接：python正则表达式re之compile函数解析<em>python</em>脚本之家  <a href="https://www.jb51.net/article/126754.htm" target="_blank" rel="noopener">https://www.jb51.net/article/126754.htm</a>)</p>
<p>链接：Python3中正则模块re.compile、re.match及re.search函数用法详解<em>python</em>脚本之家  <a href="https://www.jb51.net/article/141830.htm" target="_blank" rel="noopener">https://www.jb51.net/article/141830.htm</a></p>
<p>例如：</p>
<pre><code>&gt;&gt;&gt; content = &apos;Citizen wang , always fall in love with neighbour，WANG&apos;
&gt;&gt;&gt; rr = re.compile(r&apos;wan\w&apos;, re.I)
&gt;&gt;&gt; print(type(rr))
&lt;class &apos;_sre.SRE_Pattern&apos;&gt;
&gt;&gt;&gt; a = rr.findall(content)
&gt;&gt;&gt; print(type(a))
&lt;class &apos;list&apos;&gt;
&gt;&gt;&gt; print(a)
[&apos;wang&apos;, &apos;WANG&apos;]
&gt;&gt;&gt; print(rr)
re.compile(&apos;wan\\w&apos;, re.IGNORECASE)
</code></pre><p>findall 返回的是一个 list 对象</p>
<pre><code>&lt;class &apos;_sre.SRE_Pattern&apos;&gt;
&lt;class &apos;list&apos;&gt;
[&apos;wang&apos;, &apos;WANG&apos;]
</code></pre><h3 id="3、re-match-函数"><a href="#3、re-match-函数" class="headerlink" title="3、re.match() 函数"></a>3、re.match() 函数</h3><p>总是从字符串‘开头曲匹配’，并返回匹配的字符串的 match 对象 <class '_sre.sre_match'="">。</class></p>
<pre><code>re.match(pattern, string[, flags=0])
</code></pre><p>•pattern 匹配模式，由 re.compile 获得</p>
<p>•string 需要匹配的字符串</p>
<p>举例：</p>
<pre><code>import re

pattern = re.compile(r&apos;hello&apos;)
a = re.match(pattern, &apos;hello world&apos;)
b = re.match(pattern, &apos;world hello&apos;)
c = re.match(pattern, &apos;hell&apos;)
d = re.match(pattern, &apos;hello&apos;)

if a:
    print(a.group())
else:
    print(&apos;a failed&apos;)
if b:
    print(b.group())
else:
    print(&apos;b failed&apos;)
if c:
    print(c.group())
else:
    print(&apos;c failed&apos;)
if d:
    print(d.group())
else:
    print(&apos;d failed&apos;)


&gt;&gt;&gt; 
hello
b failed
c failed
hello
&gt;&gt;&gt; 
</code></pre><p><strong>a.group（）</strong></p>
<pre><code>&gt;&gt;&gt; print(a)
&lt;_sre.SRE_Match object; span=(0, 5), match=&apos;hello&apos;&gt;
&gt;&gt;&gt; help(a.group)
Help on built-in function group:

group(...) method of _sre.SRE_Match instance
    group([group1, ...]) -&gt; str or tuple.
    Return subgroup(s) of the match by indices or names.
    For 0 returns the entire match.
</code></pre><h3 id="match-的方法和属性："><a href="#match-的方法和属性：" class="headerlink" title="match 的方法和属性："></a>match 的方法和属性：</h3><p>参考链接：Java使用正则表达式获取子文本的方法示例<em>java</em>脚本之家  <a href="https://www.jb51.net/article/124588.htm" target="_blank" rel="noopener">https://www.jb51.net/article/124588.htm</a></p>
<p>例：</p>
<pre><code>import re
str_ = &apos;hello world! hello python&apos;
pattern = re.compile(r&apos;(?P&lt;first&gt;hell\w)(?P&lt;symbol&gt;\s)(?P&lt;last&gt;.*ld!)&apos;)
# 分组，0 组是整个 hello world!, 1组 hello，2组 ld!

match = re.match(pattern, str_)
print(&apos;group 0:&apos;, match.group(0)) # 匹配 0 组，整个字符串
print(&apos;group 1:&apos;, match.group(1)) # 匹配第一组，hello
print(&apos;group 2:&apos;, match.group(2)) # 匹配第二组，空格
print(&apos;group 3:&apos;, match.group(3)) # 匹配第三组，ld!
print(&apos;groups:&apos;, match.groups())  # groups 方法，返回一个包含所有分组匹配的元组
print(&apos;start 0:&apos;, match.start(0), &apos;end 0:&apos;, match.end(0)) # 整个匹配开始和结束的索引值
print(&apos;start 1:&apos;, match.start(1), &apos;end 1:&apos;, match.end(1))  # 第一组开始和结束的索引值
print(&apos;start 2:&apos;, match.start(1), &apos;end 2:&apos;, match.end(2)) # 第二组开始和结束的索引值
print(&apos;pos start at:&apos;, match.pos)
print(&apos;endpos end with:&apos;, match.endpos) # string 的长度
print(&apos;lastgroup 最后一个被捕获的分组的名字：&apos;, match.lastgroup)
print(&apos;lastindex 最后一个分组在文本中的索引：&apos;, match.lastindex)
print(&apos;string 匹配时候使用的文本：&apos;, match.string)
print(&apos;re 匹配时候使用的 Pattern 对象：&apos;, match.re)
print(&apos;span 返回分组匹配的 index （start(group),end(group))：&apos;, match.span(2))
</code></pre><p>输出结果：</p>
<pre><code>&gt;&gt;&gt; 
group 0: hello world!
group 1: hello
group 2:  
group 3: world!
groups: (&apos;hello&apos;, &apos; &apos;, &apos;world!&apos;)
start 0: 0 end 0: 12
start 1: 0 end 1: 5
start 2: 0 end 2: 6
pos start at: 0
endpos end with: 25
lastgroup 最后一个被捕获的分组的名字： last
lastindex 最后一个分组在文本中的索引： 3
string 匹配时候使用的文本： hello world! hello python
re 匹配时候使用的 Pattern 对象： re.compile(&apos;(?P&lt;first&gt;hell\\w)(?P&lt;symbol&gt;\\s)(?P&lt;last&gt;.*ld!)&apos;)
span 返回分组匹配的 index （start(group),end(group))： (5, 6)
&gt;&gt;&gt; 
</code></pre><h3 id="re-search-函数"><a href="#re-search-函数" class="headerlink" title="re.search 函数"></a>re.search 函数</h3><p>对整个字符串进行搜索匹配，返回第一个匹配的字符串的 match 对象。</p>
<pre><code>re.search(pattern, string[, flags=0])
</code></pre><p>•pattern 匹配模式，由 re.compile 获得</p>
<p>•string 需要匹配的字符串</p>
<p>例： </p>
<pre><code>import re
str = &apos;say hello world! hello python&apos;
pattern = re.compile(r&apos;(?P&lt;first&gt;hell\w)(?P&lt;symbol&gt;\s)(?P&lt;last&gt;.*ld!)&apos;) # 分组，0 组是整个 hello world!, 1组 hello，2组 ld!
search = re.search(pattern, str)
print(&apos;group 0:&apos;, search.group(0)) # 匹配 0 组，整个字符串
print(&apos;group 1:&apos;, search.group(1)) # 匹配第一组，hello
print(&apos;group 2:&apos;, search.group(2)) # 匹配第二组，空格
print(&apos;group 3:&apos;, search.group(3)) # 匹配第三组，ld!
print(&apos;groups:&apos;, search.groups())  # groups 方法，返回一个包含所有分组匹配的元组
print(&apos;start 0:&apos;, search.start(0), &apos;end 0:&apos;, search.end(0)) # 整个匹配开始和结束的索引值
print(&apos;start 1:&apos;, search.start(1), &apos;end 1:&apos;, search.end(1)) # 第一组开始和结束的索引值
print(&apos;start 2:&apos;, search.start(1), &apos;end 2:&apos;, search.end(2)) # 第二组开始和结束的索引值
print(&apos;pos 开始于：&apos;, search.pos)
print(&apos;endpos 结束于：&apos;, search.endpos) # string 的长度
print(&apos;lastgroup 最后一个被捕获的分组的名字：&apos;, search.lastgroup)
print(&apos;lastindex 最后一个分组在文本中的索引：&apos;, search.lastindex)
print(&apos;string 匹配时候使用的文本：&apos;, search.string)
print(&apos;re 匹配时候使用的 Pattern 对象：&apos;, search.re)
print(&apos;span 返回分组匹配的 index （start(group),end(group))：&apos;, search.span(2))
</code></pre><p><strong>注意 re.search 和 re.match 匹配的 str 的区别</strong></p>
<p>输出结果：</p>
<pre><code>&gt;&gt;&gt; 
group 0: hello world!
group 1: hello
group 2:  
group 3: world!
groups: (&apos;hello&apos;, &apos; &apos;, &apos;world!&apos;)
start 0: 4 end 0: 16
start 1: 4 end 1: 9
start 2: 4 end 2: 10
pos 开始于： 0
endpos 结束于： 29
lastgroup 最后一个被捕获的分组的名字： last
lastindex 最后一个分组在文本中的索引： 3
string 匹配时候使用的文本： say hello world! hello python
re 匹配时候使用的 Pattern 对象： re.compile(&apos;(?P&lt;first&gt;hell\\w)(?P&lt;symbol&gt;\\s)(?P&lt;last&gt;.*ld!)&apos;)
span 返回分组匹配的 index （start(group),end(group))： (9, 10)
&gt;&gt;&gt; 
</code></pre><p>JavaScript正则表达式在线测试工具：<br><a href="http://tools.jb51.net/regex/javascript" target="_blank" rel="noopener">http://tools.jb51.net/regex/javascript</a></p>
<p>正则表达式在线生成工具：<br><a href="http://tools.jb51.net/regex/create_reg" target="_blank" rel="noopener">http://tools.jb51.net/regex/create_reg</a></p>
<p>转自：（Python3中正则模块re.compile、re.match及re.search函数用法详解<em>python</em>脚本之家  <a href="https://www.jb51.net/article/141830.htm）" target="_blank" rel="noopener">https://www.jb51.net/article/141830.htm）</a></p>
<h1 id="请求库的使用值urllib"><a href="#请求库的使用值urllib" class="headerlink" title="请求库的使用值urllib"></a>请求库的使用值urllib</h1><p>转自：Python3爬虫（三）请求库的使用之urllib - Infi_chu - 博客园  <a href="https://www.cnblogs.com/Infi-chu/p/8950935.html" target="_blank" rel="noopener">https://www.cnblogs.com/Infi-chu/p/8950935.html</a></p>
<p>Python3学习笔记（urllib模块的使用） - Data&amp;Truth - 博客园  <a href="https://www.cnblogs.com/Lands-ljk/p/5447127.html" target="_blank" rel="noopener">https://www.cnblogs.com/Lands-ljk/p/5447127.html</a></p>
<p>Python3爬虫（一）HTTP相关基础 - Infi_chu - 博客园  <a href="https://www.cnblogs.com/Infi-chu/p/8942264.html" target="_blank" rel="noopener">https://www.cnblogs.com/Infi-chu/p/8942264.html</a></p>
<p>   <strong>URI、URL、URN、HTTP</strong></p>
<pre><code> URI：统一资源标志符
 URL：是URI的一个子集
 URN：是URI的另一个子集，统一资源名称
 HTTP协议：
&gt; 超文本传输协议，是一个基于“请求与响应”模式的、无状态的引用层协议。
&gt; HTTP协议采用URL作为定位网络资源的标识。
&gt; URL格式    http://host[:port][path]
</code></pre><h2 id="一、urllib库"><a href="#一、urllib库" class="headerlink" title="一、urllib库"></a>一、urllib库</h2><ol>
<li>是Python内置的HTTP请求库</li>
<li>在Python2中，由urllib和urllib2之分，而在Python3中，统一为urllib</li>
<li>主要包含模块：</li>
</ol>
<p>　　request：最基本的发送模块，用来模拟发送请求</p>
<p>　　error：异常处理模块</p>
<p>　　parse：一个工具模块</p>
<p>　　robotparser：主要用来识别robots.txt文件</p>
<p><em>注：Robots协议：</em></p>
<pre><code>1.含义Robots Exclusion Standard 网络爬虫排除标准
2.作用：网站告知网络爬虫哪些页面可以抓取，哪些不行
3.形式：在网站根目录下的robots.txt文件
4.使用：
    a.网络爬虫：自动或人工识别robots.txt，再进行内容爬取
    b.约束性：可以不遵循，但要注意法律风险
</code></pre><p><em>转自</em> Python3爬虫（二）网络爬虫的尺寸与约束 - Infi_chu - 博客园  <a href="https://www.cnblogs.com/Infi-chu/p/8943715.html" target="_blank" rel="noopener">https://www.cnblogs.com/Infi-chu/p/8943715.html</a></p>
<h2 id="二、发送请求："><a href="#二、发送请求：" class="headerlink" title="二、发送请求："></a>二、发送请求：</h2><p>   请求包括：</p>
<pre><code>1.请求方法
2.请求的网址
3.请求头
4.请求体
</code></pre><h3 id="1-urlopen"><a href="#1-urlopen" class="headerlink" title="1. urlopen()"></a>1. urlopen()</h3><p>　　urllib.request：模块提供了最基本的构造HTTP请求的方法，同时还带有处理验证(authentication)、重定向(redirection)、浏览器Cookies等</p>
<pre><code>import urllib.request
r = urllib.request.urlopen(&apos;http://www.baidu.com&apos;)
print(r.read().decode(&apos;utf-8&apos;))
print(type(r))    # &lt;class &apos;http.client.HTTPResponse&apos;&gt;
</code></pre><p>直接用urllib.request模块的urlopen（）获取页面，page的数据格式为bytes类型，需要decode（）解码，转换成str类型。</p>
<p>HTTPResponse类型的对象包括的方法：read()、readline()、readinto()、getheader(name)、getheaders()、fileno()，等</p>
<p>HTTPResponse类型的对象包括的属性：msg、version、status、reason、debuglevel、closed等</p>
<p>info(): 返回HTTPMessage对象，表示远程服务器返回的头信息</p>
<p>getcode()：返回Http状态码。如果是http请求，200请求成功完成;404网址未找到</p>
<p>geturl()：返回请求的url</p>
<pre><code>urllib.request.urlopen(url,data=None,[timeout,]*,cafile=None,capath=None,cadefault=False,context=None)
</code></pre><p>   响应包括：</p>
<pre><code>1.响应状态码

2.响应头

3.响应体
</code></pre><p><strong>1）data参数：</strong></p>
<ol>
<li>可选</li>
<li>若是字节流编码格式的内容，即bytes类型，则需要通过bytes()方法转化。若传递该参数，则请求方式会有GET变为POST</li>
<li>bytes()第一个参数需为str类型，可用urllib.parse.urlencode()方法是字典变为字符串</li>
</ol>
<p><strong>2）timeout参数：</strong></p>
<p>1、 可选</p>
<p>2.用于设置超时时间，单位是秒，默认使用全局默认时间</p>
<p>3.支持HTTP、HTTPS、FTP请求</p>
<p>4.例：</p>
<pre><code>import urllib
try:
    r = urllib.request.urlopen(&apos;http://www.baidu.com&apos;, timeout=0.1)
except urllib.error.URLError as e:
    if isinstance(e.reason, socket.timeout):
        print(&apos;Time Out!&apos;)
</code></pre><p><strong>3）context参数</strong>：必须是ssl.SSLContext类型，用来指定SSL设置</p>
<p><strong>4）cafile参数</strong>：指定CA证书</p>
<p><strong>5）capath参数</strong>：指定CA证书的路径</p>
<p><em>【注】cafile和capath一起在请求HTTPS时使用</em></p>
<p><strong>6）cadefault参数</strong>：已被废弃，默认是False</p>
<h3 id="2-Request"><a href="#2-Request" class="headerlink" title="2. Request"></a>2. Request</h3><p>urlopen()不足以构建一个完整的请求，若要加入Headers等信息，就可以用Request类</p>
<p>Request类的构造：</p>
<pre><code>class urllib.request.Request(url,data=None,headers={},origin_req_host=None,unverifiable=False,method=None)
</code></pre><p><strong>1）url参数</strong>：同urlopen()</p>
<p><strong>2）data参数</strong>：同urlopen()</p>
<p><strong>3）headers参数</strong>：</p>
<p>   1.请求头</p>
<p>   2.可以直接在字典中构造，也可以用add_header()方法添加</p>
<p>   3.可将User-Agent改为Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko)　　【注】伪造成浏览器访问</p>
<p>用来包装头部的数据：</p>
<p>   User-Agent ：这个头部可以携带如下几条信息：浏览器名和版本号、操作系统名和版本号、默认语言</p>
<p>   Referer：可以用来防止盗链，有一些网站图片显示来源http://***.com，就是检查Referer来鉴定的</p>
<p>   Connection：表示连接状态，记录Session的状态。</p>
<p><strong>4）origin_req_host参数</strong>：指的是请求方的host名称或IP地址</p>
<p><strong>5）unverifiable参数</strong>：请求是否是无法验证的，默认是False</p>
<p><strong>6）method参数</strong>：是一个字符串，用来指示请求的方法</p>
<pre><code>url = r&apos;http://www.lagou.com/zhaopin/Python/?labelWords=label&apos;
headers = {
&apos;User-Agent&apos;: r&apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) &apos;
              r&apos;Chrome/45.0.2454.85 Safari/537.36 115Browser/6.0.3&apos;,
&apos;Referer&apos;: r&apos;http://www.lagou.com/zhaopin/Python/?labelWords=label&apos;,
&apos;Connection&apos;: &apos;keep-alive&apos;
}
req = request.Request(url, headers=headers)
page = request.urlopen(req).read()
page = page.decode(&apos;utf-8&apos;)
</code></pre><h3 id="3-Handler（请求的高级用法）："><a href="#3-Handler（请求的高级用法）：" class="headerlink" title="3. Handler（请求的高级用法）："></a>3. Handler（请求的高级用法）：</h3><p>Handler是各种处理器，可以处理登录验证，可以处理Cookies，可以处理代理。</p>
<p>urllib.request模块里面的BaseHandler类，是所有其他Handler的父类。</p>
<p>各种Handler子类继承这个BaseHandler类：</p>
<p>   HTTPDefaultErrorHandler：用于处理HTTP响应错误，会抛出异常</p>
<p>   HTTPRedirectHandler：用于处理重定向</p>
<p>   HTTPCookieProcessor：用于处理Cookies</p>
<p>   ProxyHandler：用于设置代理，默认为空</p>
<p>   HTTPPasswordMgr：用于管理密码</p>
<p>   HTTPBasicAuthHandler：用于管理认证</p>
<h3 id="4-OpenDirector："><a href="#4-OpenDirector：" class="headerlink" title="4. OpenDirector："></a>4. OpenDirector：</h3><p>  应用：验证、代理、Cookies</p>
<h3 id="5-POST数据"><a href="#5-POST数据" class="headerlink" title="5.POST数据"></a>5.POST数据</h3><pre><code>urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None)
</code></pre><p>urlopen（）的data参数默认为None，当data参数不为空的时候，urlopen（）提交方式为Post。</p>
<pre><code>from urllib import request, parse
url = r&apos;http://www.lagou.com/jobs/positionAjax.json?&apos;
headers = {
    &apos;User-Agent&apos;: r&apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) &apos;
                  r&apos;Chrome/45.0.2454.85 Safari/537.36 115Browser/6.0.3&apos;,
    &apos;Referer&apos;: r&apos;http://www.lagou.com/zhaopin/Python/?labelWords=label&apos;,
    &apos;Connection&apos;: &apos;keep-alive&apos;
}
data = {
    &apos;first&apos;: &apos;true&apos;,
    &apos;pn&apos;: 1,
    &apos;kd&apos;: &apos;Python&apos;
}
data = parse.urlencode(data).encode(&apos;utf-8&apos;)
req = request.Request(url, headers=headers, data=data)
page = request.urlopen(req).read()
page = page.decode(&apos;utf-8&apos;)
</code></pre><p>urlencode（）主要作用就是将url附上要提交的数据。 </p>
<pre><code>urllib.parse.urlencode(query, doseq=False, safe=&apos;&apos;, encoding=None, errors=None)

data = {
&apos;first&apos;: &apos;true&apos;,
&apos;pn&apos;: 1,
&apos;kd&apos;: &apos;Python&apos;
}
data = parse.urlencode(data).encode(&apos;utf-8&apos;)
</code></pre><p>经过urlencode（）转换后的data数据为?first=true?pn=1?kd=Python，最后提交的url为</p>
<p>Post的数据必须是bytes或者iterable of bytes，不能是str，因此需要进行encode（）编码</p>
<pre><code>page = request.urlopen(req, data=data).read()
</code></pre><p>当然，也可以把data的数据封装在urlopen（）参数中</p>
<h3 id="GET和POST的区别"><a href="#GET和POST的区别" class="headerlink" title="GET和POST的区别"></a>GET和POST的区别</h3><p>1.GET相对于POST较不安全，GET将参数包含在URL里面，POST是通过表单形式传输的，包含在请求体中。</p>
<p>2.GET最多提交的数据大小为1024字节，POST没有限制</p>
<p>3.GET效率较高与POST</p>
<h2 id="三、异常处理："><a href="#三、异常处理：" class="headerlink" title="三、异常处理："></a>三、异常处理：</h2><h3 id="1-URLError："><a href="#1-URLError：" class="headerlink" title="1. URLError："></a>1. URLError：</h3><p>a. 来自urllib库的error模块，他继承自OSError类，是error异常模块的基类，由request模块产生的异常都可以通过它处理</p>
<p>b. reason属性，返回原因</p>
<h3 id="2-HTTPError："><a href="#2-HTTPError：" class="headerlink" title="2. HTTPError："></a>2. HTTPError：</h3><p>a. 是URLError的子类，专门用来处理HTTP请求错误</p>
<p>b. 三个属性：</p>
<p>　　　　code：返回状态码</p>
<p>　　　　reason：返回原因</p>
<p>　　　　headers：返回请求头</p>
<pre><code>def get_page(url):
    headers = {
        &apos;User-Agent&apos;: r&apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) &apos;
                    r&apos;Chrome/45.0.2454.85 Safari/537.36 115Browser/6.0.3&apos;,
        &apos;Referer&apos;: r&apos;http://www.lagou.com/zhaopin/Python/?labelWords=label&apos;,
        &apos;Connection&apos;: &apos;keep-alive&apos;
    }
    data = {
        &apos;first&apos;: &apos;true&apos;,
        &apos;pn&apos;: 1,
        &apos;kd&apos;: &apos;Python&apos;
    }
    data = parse.urlencode(data).encode(&apos;utf-8&apos;)
    req = request.Request(url, headers=headers)
    try:
        page = request.urlopen(req, data=data).read()
        page = page.decode(&apos;utf-8&apos;)
    except error.HTTPError as e:
        print(e.code())
        print(e.read().decode(&apos;utf-8&apos;))
    return page
</code></pre><h2 id="四、解析链接："><a href="#四、解析链接：" class="headerlink" title="四、解析链接："></a>四、解析链接：</h2><p>介绍parse模块中的方法，parse定义了处理URL的标准接口</p>
<h3 id="1-urlparse"><a href="#1-urlparse" class="headerlink" title="1. urlparse()"></a>1. urlparse()</h3><p>实现URL的识别分段。</p>
<p>　　API用法：　</p>
<pre><code>urllib.parse.urlparse(urlstring,scheme=&apos;&apos;,allow_fragments=True)
</code></pre><p>　　urlstring参数：必选，待解析的URL</p>
<p>　　scheme参数：它是默认的协议（HTTP、HTTPS），urlstring没有时生效</p>
<p>　　allow_fragments参数：是否忽略fragment，False为忽略，当URL中不包含params和query时，fragment会被解析为path的一部分</p>
<h3 id="2-urlunparse"><a href="#2-urlunparse" class="headerlink" title="2. urlunparse()"></a>2. urlunparse()</h3><p>与urlparse对立，接受的参数是一个可迭代对象，长度必须为6（scheme,netloc,path,params,query,fragment），可以是元组、字典等特定的数据结构，这样就可以实现URL的构造</p>
<h3 id="3-urlsplit"><a href="#3-urlsplit" class="headerlink" title="3. urlsplit()"></a>3. urlsplit()</h3><p>　　与urlparse相似，不单独解析parse，返回5各部分，元组类型</p>
<h3 id="4-urlunsplit"><a href="#4-urlunsplit" class="headerlink" title="4. urlunsplit()"></a>4. urlunsplit()</h3><p>　　与urlunparse()类似，将各个部分拼接，长度必须是5</p>
<h3 id="5-urljoin"><a href="#5-urljoin" class="headerlink" title="5. urljoin()"></a>5. urljoin()</h3><p>　　生成链接，提供一个base-url的scheme,netloc,和path 3个内容并对新链接缺失的部分进行补充。</p>
<p>　　【注】两个都有取最新的，不全的话互补</p>
<h3 id="6-urlencode"><a href="#6-urlencode" class="headerlink" title="6. urlencode()"></a>6. urlencode()</h3><p>　　在构造GET请求参数的时候很有用，将字典序列化为GET请求参数</p>
<h3 id="7-parse-qs"><a href="#7-parse-qs" class="headerlink" title="7. parse_qs()"></a>7. parse_qs()</h3><p>　　反序列化，将一串GET请求参数，转化为字典</p>
<h3 id="8-parse-qsl"><a href="#8-parse-qsl" class="headerlink" title="8. parse_qsl()"></a>8. parse_qsl()</h3><p>　　同parse_qs()，将GET转化为元组组成的列表</p>
<h3 id="9-quote"><a href="#9-quote" class="headerlink" title="9. quote()"></a>9. quote()</h3><p>　　将内容转化为URL编码的格式，因为URL有中文编码格式时，可能会出现乱码，用它可以转化</p>
<h3 id="10-unquote"><a href="#10-unquote" class="headerlink" title="10. unquote()"></a>10. unquote()</h3><p>　　进行URL解码</p>
<h2 id="五、分析robots协议："><a href="#五、分析robots协议：" class="headerlink" title="五、分析robots协议："></a>五、分析robots协议：</h2><p>robotparser模块，该模块提供了一个RobotFileParser类</p>
<pre><code>urllib.robotparser.RobotFileParser(url=&apos;&apos;)
</code></pre><p>　　此类的常用方法：</p>
<p>　　set_url()　　设置robots.txt文件的链接</p>
<p>　　read()　　读取文件并分析</p>
<p>　　parse()　　解析文件</p>
<p>　　can_fetch()　　传入两个参数，第一个是User-Agent，第二个是抓取的URL，返回是否可抓取</p>
<p>　　mtime()　　返回上回抓取和分析的时间</p>
<p>　　modified()　　将当前时间设置为上次抓取和分析的时间</p>
<h2 id="六、使用代理"><a href="#六、使用代理" class="headerlink" title="六、使用代理"></a>六、使用代理</h2><pre><code>urllib.request.ProxyHandler(proxies=None)
</code></pre><p>当需要抓取的网站设置了访问限制，这时就需要用到代理来抓取数据。</p>
<pre><code>data = {
    &apos;first&apos;: &apos;true&apos;,
    &apos;pn&apos;: 1,
    &apos;kd&apos;: &apos;Python&apos;
}
proxy = request.ProxyHandler({&apos;http&apos;: &apos;5.22.195.215:80&apos;})  # 设置proxy
opener = request.build_opener(proxy)  # 挂载opener
request.install_opener(opener)  # 安装opener
data = parse.urlencode(data).encode(&apos;utf-8&apos;)
page = opener.open(url, data).read()
page = page.decode(&apos;utf-8&apos;)
return page
</code></pre><h3 id="代理的分类"><a href="#代理的分类" class="headerlink" title="代理的分类"></a>代理的分类</h3><p><strong>1.根据协议分类：</strong></p>
<pre><code>协议　　     一般开放端口

FTP　　       21、2121

HTTP         80、8080、3128

SSL/TLS      443

RTSP　       554

Telnet　     23

POP3/SMTP　　110/25

SOCKS　　    1080
</code></pre><p><strong>2.根据匿名程度分类：</strong></p>
<pre><code>a.高度匿名代理

b.普通匿名代理

c.透明代理

d.间谍代理
</code></pre><h3 id="代理的作用"><a href="#代理的作用" class="headerlink" title="代理的作用"></a>代理的作用</h3><p>1.突破自身IP访问限制，访问一些平时不能访问的站点</p>
<p>2.访问一些单位或团体的内部资源</p>
<p>3.提高访问速度</p>
<p>4.隐藏真实IP</p>

                <hr>
                

                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2018/10/23/Github Pages和Hexo简明教程/" data-toggle="tooltip" data-placement="top"
                           title="Github Pages和Hexo简明教程">&larr; Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2018/09/05/FTP_Server_Build(win7 64)/" data-toggle="tooltip" data-placement="top"
                           title="win7下利用IIS搭建FTP服务器(转载)">Next Post &rarr;</a>
                    </li>
                    
                </ul>

                

                


                <!--加入新的评论系统-->
                

                

            </div>

            <div class="hidden-xs col-sm-3 toc-col">
                <div class="toc-wrap">
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#selenium模块的基本用法"><span class="toc-text">selenium模块的基本用法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#查找元素"><span class="toc-text">查找元素</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#元素操作之键盘操作"><span class="toc-text">元素操作之键盘操作</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#对于百度设置拦定位的问题"><span class="toc-text">对于百度设置拦定位的问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#问题1：Firefox直接选择点击设置，再次点击下拉拦是无法定位到的。（同样方法在Chrome中可定位到）"><span class="toc-text">问题1：Firefox直接选择点击设置，再次点击下拉拦是无法定位到的。（同样方法在Chrome中可定位到）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#问题2：定位时使用xpath，或css-selector定位不到，也会报错。"><span class="toc-text">问题2：定位时使用xpath，或css_selector定位不到，也会报错。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#问题3：网页通知（告警）弹窗接收问题"><span class="toc-text">问题3：网页通知（告警）弹窗接收问题</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#关于无法定位到网页元素的问题"><span class="toc-text">关于无法定位到网页元素的问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#问题1："><span class="toc-text">问题1：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#问题2："><span class="toc-text">问题2：</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#selenium：解决页面元素display-none的方法"><span class="toc-text">selenium：解决页面元素display:none的方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1、具体问题"><span class="toc-text">1、具体问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2、解决方案"><span class="toc-text">2、解决方案</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#代码解析："><span class="toc-text">代码解析：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#关于上传文件时操作windows弹窗"><span class="toc-text">关于上传文件时操作windows弹窗</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#下载文件"><span class="toc-text">下载文件</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1、对于Firefox下载文件"><span class="toc-text">1、对于Firefox下载文件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2、Chrome文件下载"><span class="toc-text">2、Chrome文件下载</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Request-模块"><span class="toc-text">Request 模块</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1、Requests库的七个主要方法"><span class="toc-text">1、Requests库的七个主要方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-requests-request"><span class="toc-text">(1) requests.request()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#（2）requests-get"><span class="toc-text">（2）requests.get()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#requests库的异常"><span class="toc-text">requests库的异常</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-request-head"><span class="toc-text">(3) request.head()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#（4）requests-post"><span class="toc-text">（4）requests.post()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#（5）requests-put"><span class="toc-text">（5）requests.put()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#（6）requests-patch"><span class="toc-text">（6）requests.patch()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#（7）requests-request"><span class="toc-text">（7）requests.request()</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-requests高级用法"><span class="toc-text">2.requests高级用法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-文件上传"><span class="toc-text">1.文件上传</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Cookies"><span class="toc-text">2.Cookies</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-会话维持"><span class="toc-text">3.会话维持</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-SSL证书认证"><span class="toc-text">4.SSL证书认证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-代理设置"><span class="toc-text">5.代理设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-超时设置"><span class="toc-text">6.超时设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-身份认证"><span class="toc-text">7.身份认证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-Prepared-Request"><span class="toc-text">8.Prepared Request</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#执行JavaScript"><span class="toc-text">执行JavaScript</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Example-1进入浏览器之后，隐藏文字和按钮，及弹出一个alert弹框"><span class="toc-text">1.Example 1进入浏览器之后，隐藏文字和按钮，及弹出一个alert弹框</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Example-2执行JS脚本来控制浏览器竖向滚动条"><span class="toc-text">2.Example 2执行JS脚本来控制浏览器竖向滚动条</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Cookies操作"><span class="toc-text">Cookies操作</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#获取验证码-识别图片文字"><span class="toc-text">获取验证码-识别图片文字</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#安装："><span class="toc-text">安装：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1、tesseract-orc"><span class="toc-text">1、tesseract-orc</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2、pytesseract"><span class="toc-text">2、pytesseract</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#配置环境变量："><span class="toc-text">配置环境变量：</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#验证码处理"><span class="toc-text">验证码处理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#简单爬取网页图片"><span class="toc-text">简单爬取网页图片</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#urllib和requests区别："><span class="toc-text">urllib和requests区别：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#扩展-re-模块："><span class="toc-text">扩展- re 模块：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1、模块总结"><span class="toc-text">1、模块总结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2、re-compile模块"><span class="toc-text">2、re.compile模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3、re-match-函数"><span class="toc-text">3、re.match() 函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#match-的方法和属性："><span class="toc-text">match 的方法和属性：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#re-search-函数"><span class="toc-text">re.search 函数</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#请求库的使用值urllib"><span class="toc-text">请求库的使用值urllib</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#一、urllib库"><span class="toc-text">一、urllib库</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二、发送请求："><span class="toc-text">二、发送请求：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-urlopen"><span class="toc-text">1. urlopen()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Request"><span class="toc-text">2. Request</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Handler（请求的高级用法）："><span class="toc-text">3. Handler（请求的高级用法）：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-OpenDirector："><span class="toc-text">4. OpenDirector：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-POST数据"><span class="toc-text">5.POST数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GET和POST的区别"><span class="toc-text">GET和POST的区别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三、异常处理："><span class="toc-text">三、异常处理：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-URLError："><span class="toc-text">1. URLError：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-HTTPError："><span class="toc-text">2. HTTPError：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#四、解析链接："><span class="toc-text">四、解析链接：</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-urlparse"><span class="toc-text">1. urlparse()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-urlunparse"><span class="toc-text">2. urlunparse()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-urlsplit"><span class="toc-text">3. urlsplit()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-urlunsplit"><span class="toc-text">4. urlunsplit()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-urljoin"><span class="toc-text">5. urljoin()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-urlencode"><span class="toc-text">6. urlencode()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-parse-qs"><span class="toc-text">7. parse_qs()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-parse-qsl"><span class="toc-text">8. parse_qsl()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-quote"><span class="toc-text">9. quote()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-unquote"><span class="toc-text">10. unquote()</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#五、分析robots协议："><span class="toc-text">五、分析robots协议：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#六、使用代理"><span class="toc-text">六、使用代理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#代理的分类"><span class="toc-text">代理的分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#代理的作用"><span class="toc-text">代理的作用</span></a></li></ol></li></ol></li></ol>
                </div>
            </div>
        </div>

        <div class="row">
            <!-- Sidebar Container -->

            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                

                <!-- Friends Blog -->
                
            </div>
        </div>

    </div>
</article>







<!-- Footer -->
<!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 text-center">
                <br>
                <ul class="list-inline text-center">
                
                
                

                

                

                

                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; Baobiy 2018
                    <br>
                    <span id="busuanzi_container_site_pv" style="font-size: 12px;">PV: <span id="busuanzi_value_site_pv"></span> Times</span>
                    <br>
                    Theme by <a href="https://haojen.github.io/">Haojen Ma</a>
                </p>

            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="/js/blog.js"></script>

<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("http://yoursite.com/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("//cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>

<!-- Google Analytics -->



<!-- Baidu Tongji -->


<!-- swiftype -->
<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install','','2.0.0');
</script>

<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<!--wechat title img-->
<img class="wechat-title-img" src="">
</body>

</html>
